{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3e314347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "080aab94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>job_title_lemmatized</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_embeddings</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>connection_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>85</td>\n",
       "      <td>2019 c t   bauer college business graduate   m...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.20800781  0.03417969  0.02575684 ...  0.0...</td>\n",
       "      <td>[-8.36746246e-02  3.46024260e-02 -1.73351355e-...</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>[[-6.1878e-01 -4.9302e-02  3.5098e-01 ... -2.4...</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.532657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>500+</td>\n",
       "      <td>native english teacher epik   english program ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[ 0.26367188  0.28125    -0.05493164 ... -0.2...</td>\n",
       "      <td>[-2.04139259e-02  1.74007919e-02  5.13645560e-...</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>[[-0.70018   0.053196 -0.20213  ... -0.22181  ...</td>\n",
       "      <td>0.409110</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>Raleigh-Durham, North Carolina Area</td>\n",
       "      <td>44</td>\n",
       "      <td>aspire human resource professional</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.07910156  0.05908203  0.16210938 ... -0.2...</td>\n",
       "      <td>[-8.61571506e-02  3.96362171e-02 -8.47534910e-...</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>[[ 0.042918   0.90274   -0.14664   ... -0.0568...</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Raleigh-Durham</td>\n",
       "      <td>North Carolina Area</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>Denton, Texas</td>\n",
       "      <td>500+</td>\n",
       "      <td>people development coordinator ryan</td>\n",
       "      <td>0</td>\n",
       "      <td>[[ 0.26367188 -0.01916504  0.02893066 ... -0.0...</td>\n",
       "      <td>[-1.06938034e-01 -1.27687156e-02 -7.28640631e-...</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>[[-0.41355   0.076012  0.099178 ...  0.15953  ...</td>\n",
       "      <td>0.509445</td>\n",
       "      <td>0.486340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Denton</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>İzmir, Türkiye</td>\n",
       "      <td>500+</td>\n",
       "      <td>advisory board member celal bayar university</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.08837891 -0.17773438  0.1953125  ... -0.0...</td>\n",
       "      <td>[-8.32213387e-02  1.65026933e-02 -7.30818463e-...</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>[[ 0.29924   -0.056401  -0.10924   ...  0.1007...</td>\n",
       "      <td>0.329143</td>\n",
       "      <td>0.282052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>İzmir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...   \n",
       "1   2  Native English Teacher at EPIK (English Progra...   \n",
       "2   3              Aspiring Human Resources Professional   \n",
       "3   4             People Development Coordinator at Ryan   \n",
       "4   5    Advisory Board Member at Celal Bayar University   \n",
       "\n",
       "                              location connection  \\\n",
       "0                       Houston, Texas         85   \n",
       "1                               Kanada      500+    \n",
       "2  Raleigh-Durham, North Carolina Area         44   \n",
       "3                        Denton, Texas      500+    \n",
       "4                       İzmir, Türkiye      500+    \n",
       "\n",
       "                                job_title_lemmatized  has_hr  \\\n",
       "0  2019 c t   bauer college business graduate   m...       1   \n",
       "1  native english teacher epik   english program ...       0   \n",
       "2                 aspire human resource professional       1   \n",
       "3                people development coordinator ryan       0   \n",
       "4       advisory board member celal bayar university       0   \n",
       "\n",
       "                                 word2vec_embeddings  \\\n",
       "0  [[-0.20800781  0.03417969  0.02575684 ...  0.0...   \n",
       "1  [[ 0.26367188  0.28125    -0.05493164 ... -0.2...   \n",
       "2  [[-0.07910156  0.05908203  0.16210938 ... -0.2...   \n",
       "3  [[ 0.26367188 -0.01916504  0.02893066 ... -0.0...   \n",
       "4  [[-0.08837891 -0.17773438  0.1953125  ... -0.0...   \n",
       "\n",
       "                                 sentence_embeddings  word2vec_max_similarity  \\\n",
       "0  [-8.36746246e-02  3.46024260e-02 -1.73351355e-...                 0.572644   \n",
       "1  [-2.04139259e-02  1.74007919e-02  5.13645560e-...                 0.236671   \n",
       "2  [-8.61571506e-02  3.96362171e-02 -8.47534910e-...                 0.903204   \n",
       "3  [-1.06938034e-01 -1.27687156e-02 -7.28640631e-...                 0.285902   \n",
       "4  [-8.32213387e-02  1.65026933e-02 -7.30818463e-...                 0.251144   \n",
       "\n",
       "                                    glove_embeddings  glove_max_similarity  \\\n",
       "0  [[-6.1878e-01 -4.9302e-02  3.5098e-01 ... -2.4...              0.559280   \n",
       "1  [[-0.70018   0.053196 -0.20213  ... -0.22181  ...              0.409110   \n",
       "2  [[ 0.042918   0.90274   -0.14664   ... -0.0568...              0.927182   \n",
       "3  [[-0.41355   0.076012  0.099178 ...  0.15953  ...              0.509445   \n",
       "4  [[ 0.29924   -0.056401  -0.10924   ...  0.1007...              0.329143   \n",
       "\n",
       "   sentence_max_similarity  seniority_score  similarity_cluster  \\\n",
       "0                 0.532657              0.0                   1   \n",
       "1                 0.185627              0.0                   1   \n",
       "2                 0.843197              0.0                   2   \n",
       "3                 0.486340              0.0                   1   \n",
       "4                 0.282052              0.0                   1   \n",
       "\n",
       "   experience_score        country            city               region  \\\n",
       "0               0.0  United States         Houston                Texas   \n",
       "1               0.0         Canada             NaN               Kanada   \n",
       "2               0.0  United States  Raleigh-Durham  North Carolina Area   \n",
       "3               0.0  United States          Denton                Texas   \n",
       "4               0.0        Türkiye           İzmir                  NaN   \n",
       "\n",
       "   connection_score  \n",
       "0             0.170  \n",
       "1             1.000  \n",
       "2             0.088  \n",
       "3             1.000  \n",
       "4             1.000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data = pd.read_csv('extracted_features_candidate_data_ver3.csv')\n",
    "featured_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bef41179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 19)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "53a19634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>connection_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.532657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.409110</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kanada</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Raleigh-Durham</td>\n",
       "      <td>North Carolina Area</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>0.509445</td>\n",
       "      <td>0.486340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Denton</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>0.329143</td>\n",
       "      <td>0.282052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Türkiye</td>\n",
       "      <td>İzmir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  has_hr  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...       1   \n",
       "1   2  Native English Teacher at EPIK (English Progra...       0   \n",
       "2   3              Aspiring Human Resources Professional       1   \n",
       "3   4             People Development Coordinator at Ryan       0   \n",
       "4   5    Advisory Board Member at Celal Bayar University       0   \n",
       "\n",
       "   word2vec_max_similarity  glove_max_similarity  sentence_max_similarity  \\\n",
       "0                 0.572644              0.559280                 0.532657   \n",
       "1                 0.236671              0.409110                 0.185627   \n",
       "2                 0.903204              0.927182                 0.843197   \n",
       "3                 0.285902              0.509445                 0.486340   \n",
       "4                 0.251144              0.329143                 0.282052   \n",
       "\n",
       "   seniority_score  similarity_cluster  experience_score        country  \\\n",
       "0              0.0                   1               0.0  United States   \n",
       "1              0.0                   1               0.0         Canada   \n",
       "2              0.0                   2               0.0  United States   \n",
       "3              0.0                   1               0.0  United States   \n",
       "4              0.0                   1               0.0        Türkiye   \n",
       "\n",
       "             city               region  connection_score  \n",
       "0         Houston                Texas             0.170  \n",
       "1             NaN               Kanada             1.000  \n",
       "2  Raleigh-Durham  North Carolina Area             0.088  \n",
       "3          Denton                Texas             1.000  \n",
       "4           İzmir                  NaN             1.000  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data_embeddings_dropped = featured_data.drop(columns=[\n",
    "    'location',\n",
    "    'connection',\n",
    "    'job_title_lemmatized',\n",
    "    'word2vec_embeddings',\n",
    "    'sentence_embeddings',\n",
    "    'glove_embeddings'\n",
    "])\n",
    "featured_data_embeddings_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef5f985e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique country count: 4\n",
      "Unique region count: 28\n",
      "Unique city count: 34\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique country count:\", featured_data_embeddings_dropped['country'].nunique())\n",
    "print(\"Unique region count:\", featured_data_embeddings_dropped['region'].nunique())\n",
    "print(\"Unique city count:\", featured_data_embeddings_dropped['city'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0f5abc0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>connection_score</th>\n",
       "      <th>country_Amerika Birleşik Devletleri</th>\n",
       "      <th>country_Canada</th>\n",
       "      <th>country_Türkiye</th>\n",
       "      <th>country_United States</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.532657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.409110</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>0.509445</td>\n",
       "      <td>0.486340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>0.329143</td>\n",
       "      <td>0.282052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  has_hr  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...       1   \n",
       "1   2  Native English Teacher at EPIK (English Progra...       0   \n",
       "2   3              Aspiring Human Resources Professional       1   \n",
       "3   4             People Development Coordinator at Ryan       0   \n",
       "4   5    Advisory Board Member at Celal Bayar University       0   \n",
       "\n",
       "   word2vec_max_similarity  glove_max_similarity  sentence_max_similarity  \\\n",
       "0                 0.572644              0.559280                 0.532657   \n",
       "1                 0.236671              0.409110                 0.185627   \n",
       "2                 0.903204              0.927182                 0.843197   \n",
       "3                 0.285902              0.509445                 0.486340   \n",
       "4                 0.251144              0.329143                 0.282052   \n",
       "\n",
       "   seniority_score  similarity_cluster  experience_score  connection_score  \\\n",
       "0              0.0                   1               0.0             0.170   \n",
       "1              0.0                   1               0.0             1.000   \n",
       "2              0.0                   2               0.0             0.088   \n",
       "3              0.0                   1               0.0             1.000   \n",
       "4              0.0                   1               0.0             1.000   \n",
       "\n",
       "   country_Amerika Birleşik Devletleri  country_Canada  country_Türkiye  \\\n",
       "0                                False           False            False   \n",
       "1                                False            True            False   \n",
       "2                                False           False            False   \n",
       "3                                False           False            False   \n",
       "4                                False           False             True   \n",
       "\n",
       "   country_United States  \n",
       "0                   True  \n",
       "1                  False  \n",
       "2                   True  \n",
       "3                   True  \n",
       "4                  False  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'city' and 'region' columns\n",
    "featured_data_encoded = featured_data_embeddings_dropped.drop(columns=['city', 'region'])\n",
    "\n",
    "# One-hot encode the 'country' categorical feature\n",
    "featured_data_encoded = pd.get_dummies(featured_data_encoded, columns=['country'])\n",
    "\n",
    "featured_data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d319f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 14)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8427a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>connection_score</th>\n",
       "      <th>country_1</th>\n",
       "      <th>country_2</th>\n",
       "      <th>country_3</th>\n",
       "      <th>country_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019 C.T. Bauer College of Business Graduate (...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572644</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>0.532657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Native English Teacher at EPIK (English Progra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236671</td>\n",
       "      <td>0.409110</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Aspiring Human Resources Professional</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>People Development Coordinator at Ryan</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>0.509445</td>\n",
       "      <td>0.486340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Advisory Board Member at Celal Bayar University</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251144</td>\n",
       "      <td>0.329143</td>\n",
       "      <td>0.282052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                          job_title  has_hr  \\\n",
       "0   1  2019 C.T. Bauer College of Business Graduate (...       1   \n",
       "1   2  Native English Teacher at EPIK (English Progra...       0   \n",
       "2   3              Aspiring Human Resources Professional       1   \n",
       "3   4             People Development Coordinator at Ryan       0   \n",
       "4   5    Advisory Board Member at Celal Bayar University       0   \n",
       "\n",
       "   word2vec_max_similarity  glove_max_similarity  sentence_max_similarity  \\\n",
       "0                 0.572644              0.559280                 0.532657   \n",
       "1                 0.236671              0.409110                 0.185627   \n",
       "2                 0.903204              0.927182                 0.843197   \n",
       "3                 0.285902              0.509445                 0.486340   \n",
       "4                 0.251144              0.329143                 0.282052   \n",
       "\n",
       "   seniority_score  similarity_cluster  experience_score  connection_score  \\\n",
       "0              0.0                   1               0.0             0.170   \n",
       "1              0.0                   1               0.0             1.000   \n",
       "2              0.0                   2               0.0             0.088   \n",
       "3              0.0                   1               0.0             1.000   \n",
       "4              0.0                   1               0.0             1.000   \n",
       "\n",
       "   country_1  country_2  country_3  country_4  \n",
       "0      False      False      False       True  \n",
       "1      False       True      False      False  \n",
       "2      False      False      False       True  \n",
       "3      False      False      False       True  \n",
       "4      False      False       True      False  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the 3 country columns in featured_data_encoded\n",
    "country_columns = [\n",
    "    'country_Amerika Birleşik Devletleri',\n",
    "    'country_Canada',\n",
    "    'country_Türkiye',\n",
    "    'country_United States'\n",
    "]\n",
    "new_country_columns = ['country_1', 'country_2', 'country_3', 'country_4']\n",
    "\n",
    "featured_data_encoded = featured_data_encoded.rename(\n",
    "    columns=dict(zip(country_columns, new_country_columns))\n",
    ")\n",
    "\n",
    "featured_data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d1eba",
   "metadata": {},
   "source": [
    "#### Will be using only glove similarity here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e06ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class InitialRanker:\n",
    "    def __init__(self):\n",
    "        self.feature_weights = {\n",
    "            'glove_max_similarity': 0.4,    \n",
    "            'has_hr': 0.25,\n",
    "            'seniority_score': 0.15,\n",
    "            'connection_score': 0.075,\n",
    "            'country_1': 0.025,\n",
    "            'country_2': 0.025,\n",
    "            'country_3': 0.025,\n",
    "            'country_4': 0.025,\n",
    "            'experience_score':0.025,\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def rank_results(self, features_df):\n",
    "        # Normalize features\n",
    "        normalized_features = self.scaler.fit_transform(features_df)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        scores = np.zeros(len(features_df))\n",
    "        for i, (feature, weight) in enumerate(self.feature_weights.items()):\n",
    "            scores += weight * normalized_features[:, i]\n",
    "        \n",
    "        # Min-max scale scores to [0, 1]\n",
    "        min_score = scores.min()\n",
    "        max_score = scores.max()\n",
    "        if max_score > min_score:\n",
    "            scores_scaled = (scores - min_score) / (max_score - min_score)\n",
    "        else:\n",
    "            scores_scaled = np.zeros_like(scores)\n",
    "        \n",
    "        # Return ranked indices and scaled scores\n",
    "        ranked_indices = np.argsort(scores_scaled)[::-1]\n",
    "        return ranked_indices, scores_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "324f8331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "job_title                  0\n",
       "has_hr                     0\n",
       "word2vec_max_similarity    0\n",
       "glove_max_similarity       0\n",
       "sentence_max_similarity    0\n",
       "seniority_score            0\n",
       "similarity_cluster         0\n",
       "experience_score           0\n",
       "connection_score           0\n",
       "country_1                  0\n",
       "country_2                  0\n",
       "country_3                  0\n",
       "country_4                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data_encoded.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e617d4a",
   "metadata": {},
   "source": [
    "#### Weight based Initial ranking system without a ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b20f8cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>connection_score</th>\n",
       "      <th>country_1</th>\n",
       "      <th>country_2</th>\n",
       "      <th>country_3</th>\n",
       "      <th>country_4</th>\n",
       "      <th>rank</th>\n",
       "      <th>scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>66</td>\n",
       "      <td>Experienced Retail Manager and aspiring Human ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777616</td>\n",
       "      <td>0.845250</td>\n",
       "      <td>0.681646</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852135</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.619586</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.795570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>HR Senior Specialist</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778913</td>\n",
       "      <td>0.824274</td>\n",
       "      <td>0.802708</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>0.779280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>84</td>\n",
       "      <td>Human Resources professional for the world lea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.807354</td>\n",
       "      <td>0.836619</td>\n",
       "      <td>0.589210</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.772234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>89</td>\n",
       "      <td>Director Human Resources  at EY</td>\n",
       "      <td>1</td>\n",
       "      <td>0.675315</td>\n",
       "      <td>0.759261</td>\n",
       "      <td>0.685894</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>0.759849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          job_title  has_hr  \\\n",
       "14  66  Experienced Retail Manager and aspiring Human ...       1   \n",
       "21  73  Aspiring Human Resources Manager, seeking inte...       1   \n",
       "7    8                               HR Senior Specialist       1   \n",
       "32  84  Human Resources professional for the world lea...       1   \n",
       "37  89                    Director Human Resources  at EY       1   \n",
       "\n",
       "    word2vec_max_similarity  glove_max_similarity  sentence_max_similarity  \\\n",
       "14                 0.777616              0.845250                 0.681646   \n",
       "21                 0.852135              0.910535                 0.619586   \n",
       "7                  0.778913              0.824274                 0.802708   \n",
       "32                 0.807354              0.836619                 0.589210   \n",
       "37                 0.675315              0.759261                 0.685894   \n",
       "\n",
       "    seniority_score  similarity_cluster  experience_score  connection_score  \\\n",
       "14             0.70                   2               1.0             0.114   \n",
       "21             0.70                   2               0.0             0.014   \n",
       "7              0.75                   2               0.0             1.000   \n",
       "32             0.80                   2               0.0             0.100   \n",
       "37             0.90                   0               0.0             0.698   \n",
       "\n",
       "    country_1  country_2  country_3  country_4  rank  scaled_score  \n",
       "14      False      False      False       True     1      1.000000  \n",
       "21      False      False      False       True     2      0.795570  \n",
       "7       False      False      False       True     3      0.779280  \n",
       "32      False      False      False       True     4      0.772234  \n",
       "37      False      False      False       True     5      0.759849  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_data = featured_data_encoded.drop(columns=['id','job_title', 'word2vec_max_similarity','sentence_max_similarity','id','similarity_cluster'], axis=1)\n",
    "\n",
    "# Select the features to use for ranking based on InitialRanker.feature_weights\n",
    "features_for_ranking = req_data.columns\n",
    "\n",
    "# Extract the relevant features from the dataframe\n",
    "features_df = featured_data_encoded[features_for_ranking]\n",
    "\n",
    "# Instantiate the ranker and get the ranked indices\n",
    "ranker = InitialRanker()\n",
    "ranked_indices, scores = ranker.rank_results(features_df)\n",
    "\n",
    "# Add a 'rank' column to the dataframe based on the ranking\n",
    "featured_data_encoded['rank'] = 0\n",
    "featured_data_encoded.loc[ranked_indices, 'rank'] = range(1, len(featured_data_encoded) + 1)\n",
    "\n",
    "featured_data_encoded['scaled_score'] = 0.0\n",
    "featured_data_encoded.loc[ranked_indices, 'scaled_score'] = scores[ranked_indices]\n",
    "\n",
    "# Display the top 10 ranked entries\n",
    "featured_data_encoded.sort_values('rank').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290378d0",
   "metadata": {},
   "source": [
    "#### Randomly star one candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8aa55baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_hr                         1\n",
       "glove_max_similarity    0.777678\n",
       "seniority_score              0.7\n",
       "experience_score             0.0\n",
       "connection_score           0.206\n",
       "country_1                  False\n",
       "country_2                  False\n",
       "country_3                  False\n",
       "country_4                   True\n",
       "Name: 48, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly star one candidate among the ranked candidates\n",
    "np.random.seed(45)  # For reproducibility\n",
    "random_star_idx = np.random.choice(ranked_indices)\n",
    "\n",
    "# Compute new feature weights based on correlation with the starred candidate\n",
    "starred_features = features_df.loc[random_star_idx].values\n",
    "all_features = features_df.values\n",
    "\n",
    "features_df.loc[random_star_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7f5eebfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0.77767754, 0.7, 0.0, 0.206, False, False, False, True],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starred_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "adb25f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0.5592798 0.0 0.0 0.17 False False False True]\n",
      " [0 0.40910956 0.0 0.0 1.0 False True False False]\n",
      " [1 0.92718184 0.0 0.0 0.088 False False False True]\n",
      " [0 0.5094455 0.0 0.0 1.0 False False False True]\n",
      " [0 0.32914257 0.0 0.0 1.0 False False True False]\n",
      " [1 0.84144753 0.6 0.0 0.002 False False False True]\n",
      " [1 0.6664656 0.0 0.0 0.122 False True False False]\n",
      " [1 0.82427436 0.75 0.0 1.0 False False False True]\n",
      " [1 0.91596663 0.0 0.0 1.0 False False False True]\n",
      " [0 0.3684305 0.0 0.0 0.004 False False False True]\n",
      " [1 0.699335 1.0 0.0 1.0 False False False True]\n",
      " [1 0.59733087 0.9 0.0 1.0 False False False True]\n",
      " [1 0.8064305 0.05 0.0 1.0 False False False True]\n",
      " [1 0.9587977 0.0 0.0 0.78 False False False True]\n",
      " [1 0.8452498 0.7 1.0 0.114 False False False True]\n",
      " [1 0.8798246 0.0 0.0 1.0 False False False True]\n",
      " [1 0.73507535 0.6 0.0 1.0 False False False True]\n",
      " [1 0.6536836 0.9 0.0 1.0 False False False True]\n",
      " [1 0.6805555 0.7 0.0 0.164 False False False True]\n",
      " [1 0.763849 0.0 0.0 1.0 False False False True]\n",
      " [1 0.7885311 0.7 0.0 0.01 False False False True]\n",
      " [1 0.91053474 0.7 0.0 0.014 False False False True]\n",
      " [1 1.0 0.0 0.0 0.032 False False False True]\n",
      " [1 0.69444346 0.0 0.0 1.0 False False False True]\n",
      " [1 0.7833528 0.0 0.0 0.424 False False False True]\n",
      " [1 0.74344957 0.0 0.0 0.818 False False False True]\n",
      " [1 0.6549085 0.0 0.0 1.0 False False False True]\n",
      " [1 0.723327 0.0 0.0 0.014 False False False True]\n",
      " [0 0.46001926 0.2 0.0 0.104 False False False True]\n",
      " [1 0.77398264 0.75 0.0 0.91 False False False True]\n",
      " [1 0.76707214 0.8 0.0 0.348 False False False True]\n",
      " [1 0.6530646 0.7 0.0 0.536 False False False True]\n",
      " [1 0.83661866 0.8 0.0 0.1 False False False True]\n",
      " [0 0.30359635 0.95 0.0 1.0 False False False True]\n",
      " [0 0.6049871 0.6 0.0 0.008 False False False True]\n",
      " [0 0.4131854 0.0 0.0 0.08 False False False True]\n",
      " [1 0.8514869 0.0 0.0 0.036 False False False True]\n",
      " [1 0.7592608 0.9 0.0 0.698 False False False True]\n",
      " [0 0.48657262 0.0 0.0 0.31 False False False True]\n",
      " [0 0.45115584 0.8 0.0 0.078 False False False True]\n",
      " [0 0.65397304 0.0 0.0 0.128 False False False True]\n",
      " [0 0.52256966 0.0 0.0 0.018 False False False True]\n",
      " [0 0.86116177 0.0 0.0 0.83 True False False False]\n",
      " [0 0.38451475 0.0 0.0 0.114 False False False True]\n",
      " [0 0.4635079 0.7 0.0 0.038 False False False True]\n",
      " [1 0.92718184 0.0 0.0 0.142 False False False True]\n",
      " [0 0.40640005 0.0 0.0 0.008 False False False True]\n",
      " [1 0.9395267 0.0 0.0 0.096 False False False True]\n",
      " [1 0.77767754 0.7 0.0 0.206 False False False True]\n",
      " [1 0.79672617 0.0 0.0 1.0 False False False True]\n",
      " [0 0.42366898 0.0 0.0 0.098 False False False True]\n",
      " [0 0.39535093 0.0 0.0 1.0 False False False True]\n",
      " [0 0.5512982 0.9 0.0 1.0 False False False True]]\n"
     ]
    }
   ],
   "source": [
    "print(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "265f62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53 entries, 0 to 52\n",
      "Data columns (total 19 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       53 non-null     int64  \n",
      " 1   job_title                53 non-null     object \n",
      " 2   location                 53 non-null     object \n",
      " 3   connection               53 non-null     object \n",
      " 4   job_title_lemmatized     53 non-null     object \n",
      " 5   has_hr                   53 non-null     int64  \n",
      " 6   word2vec_embeddings      53 non-null     object \n",
      " 7   sentence_embeddings      53 non-null     object \n",
      " 8   word2vec_max_similarity  53 non-null     float64\n",
      " 9   glove_embeddings         53 non-null     object \n",
      " 10  glove_max_similarity     53 non-null     float64\n",
      " 11  sentence_max_similarity  53 non-null     float64\n",
      " 12  seniority_score          53 non-null     float64\n",
      " 13  similarity_cluster       53 non-null     int64  \n",
      " 14  experience_score         53 non-null     float64\n",
      " 15  country                  53 non-null     object \n",
      " 16  city                     48 non-null     object \n",
      " 17  region                   51 non-null     object \n",
      " 18  connection_score         53 non-null     float64\n",
      "dtypes: float64(6), int64(3), object(10)\n",
      "memory usage: 8.0+ KB\n"
     ]
    }
   ],
   "source": [
    "featured_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8cd1f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                       100\n",
       "job_title                  Aspiring Human Resources Manager | Graduating ...\n",
       "location                                            Cape Girardeau, Missouri\n",
       "connection                                                               103\n",
       "job_title_lemmatized       aspire human resource manager   graduating 202...\n",
       "has_hr                                                                     1\n",
       "word2vec_embeddings        [[-0.07910156  0.05908203  0.16210938 ... -0.2...\n",
       "sentence_embeddings        [-3.10261883e-02  5.98907331e-03 -1.84671171e-...\n",
       "word2vec_max_similarity                                             0.733545\n",
       "glove_embeddings           [[ 0.042918   0.90274   -0.14664   ... -0.0568...\n",
       "glove_max_similarity                                                0.777678\n",
       "sentence_max_similarity                                             0.646315\n",
       "seniority_score                                                          0.7\n",
       "similarity_cluster                                                         0\n",
       "experience_score                                                         0.0\n",
       "country                                                        United States\n",
       "city                                                          Cape Girardeau\n",
       "region                                                              Missouri\n",
       "connection_score                                                       0.206\n",
       "Name: 48, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featured_data.loc[random_star_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424809a1",
   "metadata": {},
   "source": [
    "#### Extracting the glove embeddings for this entry and computing the similarity scores with the other entries and then re-ranking based on the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f574549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def max_cosine_similarity(embeddings, keyword_embs):\n",
    "    \"\"\"\n",
    "    Compute cosine similarities between all keyword embeddings and a candidate embedding,\n",
    "    and return the maximum similarity.\n",
    "    \"\"\"\n",
    "    if embeddings is None or callable(embeddings):\n",
    "        return None\n",
    "    # Each candidate embedding may be a list of token vectors (Word2Vec/Glove) or a single vector (SentenceTransformer)\n",
    "    # For token embeddings, average to get a single vector\n",
    "    if isinstance(embeddings, list) or (isinstance(embeddings, np.ndarray) and embeddings.ndim == 2):\n",
    "        if len(embeddings) == 0:\n",
    "            return None\n",
    "        candidate_vec = np.mean(np.array(embeddings), axis=0)\n",
    "    else:\n",
    "        candidate_vec = np.array(embeddings)\n",
    "\n",
    "    max_sim = None\n",
    "    for keyword_emb in keyword_embs:\n",
    "        # For token embeddings, average to get a single vector\n",
    "        if isinstance(keyword_emb, list) or (isinstance(keyword_emb, np.ndarray) and keyword_emb.ndim == 2):\n",
    "            keyword_vec = np.mean(np.array(keyword_emb), axis=0)\n",
    "        else:\n",
    "            keyword_vec = np.array(keyword_emb)\n",
    "        sim = cosine_similarity(\n",
    "            keyword_vec.reshape(1, -1),\n",
    "            candidate_vec.reshape(1, -1)\n",
    "        )[0, 0]\n",
    "        if (max_sim is None) or (sim > max_sim):\n",
    "            max_sim = sim\n",
    "    return max_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d11826c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "stored_glove_embeddings = pickle.load(open('glove_embeddings.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "54fcd28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>location</th>\n",
       "      <th>connection</th>\n",
       "      <th>job_title_lemmatized</th>\n",
       "      <th>has_hr</th>\n",
       "      <th>word2vec_embeddings</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "      <th>word2vec_max_similarity</th>\n",
       "      <th>glove_embeddings</th>\n",
       "      <th>glove_max_similarity</th>\n",
       "      <th>sentence_max_similarity</th>\n",
       "      <th>seniority_score</th>\n",
       "      <th>similarity_cluster</th>\n",
       "      <th>experience_score</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>connection_score</th>\n",
       "      <th>glove_similarity_with_starred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>100</td>\n",
       "      <td>Aspiring Human Resources Manager | Graduating ...</td>\n",
       "      <td>Cape Girardeau, Missouri</td>\n",
       "      <td>103</td>\n",
       "      <td>aspire human resource manager   graduating 202...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.07910156  0.05908203  0.16210938 ... -0.2...</td>\n",
       "      <td>[-3.10261883e-02  5.98907331e-03 -1.84671171e-...</td>\n",
       "      <td>0.733545</td>\n",
       "      <td>[[ 0.042918   0.90274   -0.14664   ... -0.0568...</td>\n",
       "      <td>0.777678</td>\n",
       "      <td>0.646315</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Cape Girardeau</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>0.206</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>99</td>\n",
       "      <td>Seeking Human Resources Position</td>\n",
       "      <td>Las Vegas, Nevada Area</td>\n",
       "      <td>48</td>\n",
       "      <td>seek human resource position</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.05517578  0.17578125 -0.08349609 ...  0.1...</td>\n",
       "      <td>[-2.43909173e-02  6.71841670e-03 -2.13245172e-...</td>\n",
       "      <td>0.919917</td>\n",
       "      <td>[[-0.10193   -0.34347   -0.4262    ... -0.0883...</td>\n",
       "      <td>0.939527</td>\n",
       "      <td>0.886942</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Nevada Area</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.830688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>73</td>\n",
       "      <td>Aspiring Human Resources Manager, seeking inte...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>7</td>\n",
       "      <td>aspire human resource manager   seek internshi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.07910156  0.05908203  0.16210938 ... -0.2...</td>\n",
       "      <td>[-4.06365134e-02  8.03943444e-03 -2.52593569e-...</td>\n",
       "      <td>0.852135</td>\n",
       "      <td>[[ 0.042918   0.90274   -0.14664   ... -0.0568...</td>\n",
       "      <td>0.910535</td>\n",
       "      <td>0.619586</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas Area</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.822043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>72</td>\n",
       "      <td>Business Management Major and Aspiring Human R...</td>\n",
       "      <td>Monroe, Louisiana Area</td>\n",
       "      <td>5</td>\n",
       "      <td>business management major aspire human resourc...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[ 0.01037598 -0.04858398 -0.12695312 ...  0.1...</td>\n",
       "      <td>[-5.28264903e-02  2.68148333e-02 -6.07161596e-...</td>\n",
       "      <td>0.745004</td>\n",
       "      <td>[[ 0.0097015  0.25098    0.22338   ... -0.3869...</td>\n",
       "      <td>0.788531</td>\n",
       "      <td>0.652678</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Monroe</td>\n",
       "      <td>Louisiana Area</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.809469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>82</td>\n",
       "      <td>Aspiring Human Resources Professional | An ene...</td>\n",
       "      <td>Austin, Texas Area</td>\n",
       "      <td>174</td>\n",
       "      <td>aspire human resource professional   energetic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.07910156  0.05908203  0.16210938 ... -0.2...</td>\n",
       "      <td>[-2.18979139e-02  1.02870487e-01 -7.19183534e-...</td>\n",
       "      <td>0.730339</td>\n",
       "      <td>[[ 0.042918   0.90274   -0.14664   ... -0.0568...</td>\n",
       "      <td>0.767072</td>\n",
       "      <td>0.641013</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas Area</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.803609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>Aspiring Human Resources Management student se...</td>\n",
       "      <td>Houston, Texas Area</td>\n",
       "      <td>500+</td>\n",
       "      <td>aspire human resource management student seek ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.07910156  0.05908203  0.16210938 ... -0.2...</td>\n",
       "      <td>[-1.67310834e-02  3.75464349e-03 -3.15526687e-...</td>\n",
       "      <td>0.746653</td>\n",
       "      <td>[[ 0.042918   0.90274   -0.14664   ... -0.0568...</td>\n",
       "      <td>0.806431</td>\n",
       "      <td>0.542803</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas Area</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.788392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28</td>\n",
       "      <td>Seeking Human Resources Opportunities</td>\n",
       "      <td>Chicago, Illinois</td>\n",
       "      <td>390</td>\n",
       "      <td>seek human resource opportunity</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-0.05517578  0.17578125 -0.08349609 ...  0.1...</td>\n",
       "      <td>[-2.53729746e-02  2.00322401e-02 -7.65634235e-...</td>\n",
       "      <td>0.906251</td>\n",
       "      <td>[[-0.10193   -0.34347   -0.4262    ... -0.0883...</td>\n",
       "      <td>0.958798</td>\n",
       "      <td>0.849017</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.786352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>94</td>\n",
       "      <td>Seeking Human  Resources Opportunities. Open t...</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>415</td>\n",
       "      <td>seek human   resource opportunity   open trave...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[-0.05517578  0.17578125 -0.08349609 ...  0.1...</td>\n",
       "      <td>[ 1.04936764e-01 -6.53318688e-02  1.24070758e-...</td>\n",
       "      <td>0.755784</td>\n",
       "      <td>[[-0.10193   -0.34347   -0.4262    ... -0.0883...</td>\n",
       "      <td>0.861162</td>\n",
       "      <td>0.507269</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Amerika Birleşik Devletleri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.780805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>88</td>\n",
       "      <td>Human Resources Management Major</td>\n",
       "      <td>Milpitas, California</td>\n",
       "      <td>18</td>\n",
       "      <td>human resource management major</td>\n",
       "      <td>1</td>\n",
       "      <td>[[ 0.0559082   0.09228516  0.10791016 ... -0.0...</td>\n",
       "      <td>[-4.21226434e-02  5.29333912e-02 -2.60268748e-...</td>\n",
       "      <td>0.821198</td>\n",
       "      <td>[[ 0.16608    0.3167    -0.58249   ...  0.2401...</td>\n",
       "      <td>0.851487</td>\n",
       "      <td>0.755799</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Milpitas</td>\n",
       "      <td>California</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.775240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>70</td>\n",
       "      <td>Retired Army National Guard Recruiter, office ...</td>\n",
       "      <td>Virginia Beach, Virginia</td>\n",
       "      <td>82</td>\n",
       "      <td>retire army national guard recruiter   office ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[[ 0.10888672 -0.18066406 -0.21484375 ... -0.1...</td>\n",
       "      <td>[-1.11894563e-01  7.35382829e-03 -5.18809147e-...</td>\n",
       "      <td>0.578547</td>\n",
       "      <td>[[-0.28577   -0.12945    0.29774   ... -0.6760...</td>\n",
       "      <td>0.680555</td>\n",
       "      <td>0.564994</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Virginia Beach</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.771852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                          job_title  \\\n",
       "48  100  Aspiring Human Resources Manager | Graduating ...   \n",
       "47   99                   Seeking Human Resources Position   \n",
       "21   73  Aspiring Human Resources Manager, seeking inte...   \n",
       "20   72  Business Management Major and Aspiring Human R...   \n",
       "30   82  Aspiring Human Resources Professional | An ene...   \n",
       "12   27  Aspiring Human Resources Management student se...   \n",
       "13   28              Seeking Human Resources Opportunities   \n",
       "42   94  Seeking Human  Resources Opportunities. Open t...   \n",
       "36   88                   Human Resources Management Major   \n",
       "18   70  Retired Army National Guard Recruiter, office ...   \n",
       "\n",
       "                       location connection  \\\n",
       "48     Cape Girardeau, Missouri        103   \n",
       "47       Las Vegas, Nevada Area         48   \n",
       "21          Houston, Texas Area          7   \n",
       "20       Monroe, Louisiana Area          5   \n",
       "30           Austin, Texas Area        174   \n",
       "12          Houston, Texas Area      500+    \n",
       "13            Chicago, Illinois        390   \n",
       "42  Amerika Birleşik Devletleri        415   \n",
       "36         Milpitas, California         18   \n",
       "18     Virginia Beach, Virginia         82   \n",
       "\n",
       "                                 job_title_lemmatized  has_hr  \\\n",
       "48  aspire human resource manager   graduating 202...       1   \n",
       "47                       seek human resource position       1   \n",
       "21  aspire human resource manager   seek internshi...       1   \n",
       "20  business management major aspire human resourc...       1   \n",
       "30  aspire human resource professional   energetic...       1   \n",
       "12  aspire human resource management student seek ...       1   \n",
       "13                    seek human resource opportunity       1   \n",
       "42  seek human   resource opportunity   open trave...       0   \n",
       "36                    human resource management major       1   \n",
       "18  retire army national guard recruiter   office ...       1   \n",
       "\n",
       "                                  word2vec_embeddings  \\\n",
       "48  [[-0.07910156  0.05908203  0.16210938 ... -0.2...   \n",
       "47  [[-0.05517578  0.17578125 -0.08349609 ...  0.1...   \n",
       "21  [[-0.07910156  0.05908203  0.16210938 ... -0.2...   \n",
       "20  [[ 0.01037598 -0.04858398 -0.12695312 ...  0.1...   \n",
       "30  [[-0.07910156  0.05908203  0.16210938 ... -0.2...   \n",
       "12  [[-0.07910156  0.05908203  0.16210938 ... -0.2...   \n",
       "13  [[-0.05517578  0.17578125 -0.08349609 ...  0.1...   \n",
       "42  [[-0.05517578  0.17578125 -0.08349609 ...  0.1...   \n",
       "36  [[ 0.0559082   0.09228516  0.10791016 ... -0.0...   \n",
       "18  [[ 0.10888672 -0.18066406 -0.21484375 ... -0.1...   \n",
       "\n",
       "                                  sentence_embeddings  \\\n",
       "48  [-3.10261883e-02  5.98907331e-03 -1.84671171e-...   \n",
       "47  [-2.43909173e-02  6.71841670e-03 -2.13245172e-...   \n",
       "21  [-4.06365134e-02  8.03943444e-03 -2.52593569e-...   \n",
       "20  [-5.28264903e-02  2.68148333e-02 -6.07161596e-...   \n",
       "30  [-2.18979139e-02  1.02870487e-01 -7.19183534e-...   \n",
       "12  [-1.67310834e-02  3.75464349e-03 -3.15526687e-...   \n",
       "13  [-2.53729746e-02  2.00322401e-02 -7.65634235e-...   \n",
       "42  [ 1.04936764e-01 -6.53318688e-02  1.24070758e-...   \n",
       "36  [-4.21226434e-02  5.29333912e-02 -2.60268748e-...   \n",
       "18  [-1.11894563e-01  7.35382829e-03 -5.18809147e-...   \n",
       "\n",
       "    word2vec_max_similarity  \\\n",
       "48                 0.733545   \n",
       "47                 0.919917   \n",
       "21                 0.852135   \n",
       "20                 0.745004   \n",
       "30                 0.730339   \n",
       "12                 0.746653   \n",
       "13                 0.906251   \n",
       "42                 0.755784   \n",
       "36                 0.821198   \n",
       "18                 0.578547   \n",
       "\n",
       "                                     glove_embeddings  glove_max_similarity  \\\n",
       "48  [[ 0.042918   0.90274   -0.14664   ... -0.0568...              0.777678   \n",
       "47  [[-0.10193   -0.34347   -0.4262    ... -0.0883...              0.939527   \n",
       "21  [[ 0.042918   0.90274   -0.14664   ... -0.0568...              0.910535   \n",
       "20  [[ 0.0097015  0.25098    0.22338   ... -0.3869...              0.788531   \n",
       "30  [[ 0.042918   0.90274   -0.14664   ... -0.0568...              0.767072   \n",
       "12  [[ 0.042918   0.90274   -0.14664   ... -0.0568...              0.806431   \n",
       "13  [[-0.10193   -0.34347   -0.4262    ... -0.0883...              0.958798   \n",
       "42  [[-0.10193   -0.34347   -0.4262    ... -0.0883...              0.861162   \n",
       "36  [[ 0.16608    0.3167    -0.58249   ...  0.2401...              0.851487   \n",
       "18  [[-0.28577   -0.12945    0.29774   ... -0.6760...              0.680555   \n",
       "\n",
       "    sentence_max_similarity  seniority_score  similarity_cluster  \\\n",
       "48                 0.646315             0.70                   0   \n",
       "47                 0.886942             0.00                   2   \n",
       "21                 0.619586             0.70                   2   \n",
       "20                 0.652678             0.70                   0   \n",
       "30                 0.641013             0.80                   0   \n",
       "12                 0.542803             0.05                   2   \n",
       "13                 0.849017             0.00                   2   \n",
       "42                 0.507269             0.00                   2   \n",
       "36                 0.755799             0.00                   2   \n",
       "18                 0.564994             0.70                   0   \n",
       "\n",
       "    experience_score                      country            city  \\\n",
       "48               0.0                United States  Cape Girardeau   \n",
       "47               0.0                United States       Las Vegas   \n",
       "21               0.0                United States         Houston   \n",
       "20               0.0                United States          Monroe   \n",
       "30               0.0                United States          Austin   \n",
       "12               0.0                United States         Houston   \n",
       "13               0.0                United States         Chicago   \n",
       "42               0.0  Amerika Birleşik Devletleri             NaN   \n",
       "36               0.0                United States        Milpitas   \n",
       "18               0.0                United States  Virginia Beach   \n",
       "\n",
       "            region  connection_score  glove_similarity_with_starred  \n",
       "48        Missouri             0.206                       1.000000  \n",
       "47     Nevada Area             0.096                       0.830688  \n",
       "21      Texas Area             0.014                       0.822043  \n",
       "20  Louisiana Area             0.010                       0.809469  \n",
       "30      Texas Area             0.348                       0.803609  \n",
       "12      Texas Area             1.000                       0.788392  \n",
       "13        Illinois             0.780                       0.786352  \n",
       "42             NaN             0.830                       0.780805  \n",
       "36      California             0.036                       0.775240  \n",
       "18        Virginia             0.164                       0.771852  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Get the id of the randomly starred candidate\n",
    "starred_id = featured_data.loc[random_star_idx, 'id']\n",
    "\n",
    "# Get the starred candidate's glove embedding\n",
    "starred_embedding = stored_glove_embeddings[float(starred_id)].mean(axis=0).reshape(1, -1)\n",
    "\n",
    "# Prepare all candidate glove embeddings (mean-pooled)\n",
    "all_ids = featured_data['id'].astype(float).values\n",
    "all_embeddings = np.array([\n",
    "    stored_glove_embeddings[id_].mean(axis=0) if id_ in stored_glove_embeddings else np.zeros(starred_embedding.shape[1])\n",
    "    for id_ in all_ids\n",
    "])\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "similarity_scores = cosine_similarity(starred_embedding, all_embeddings)[0]\n",
    "\n",
    "# Add similarity scores to the dataframe\n",
    "featured_data['glove_similarity_with_starred'] = similarity_scores\n",
    "\n",
    "# Show top 10 most similar candidates\n",
    "featured_data.sort_values('glove_similarity_with_starred', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df2f86",
   "metadata": {},
   "source": [
    "#### Another method: trying to find out the effect of the starring process on the different features used in the initial ranking algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae3ad7",
   "metadata": {},
   "source": [
    "#### The process is built on a constrained optimization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fa0d2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, linprog\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "def optimization_process(all_features, starred_idx, w_original,handle_duplicates=True, epsilon=1e-3):\n",
    "    \"\"\"\n",
    "    Guaranteed method to place starred entry at rank 1\n",
    "    \"\"\"\n",
    "\n",
    "    processed_features = all_features.copy()\n",
    "    \n",
    "    x_starred = processed_features[starred_idx]\n",
    "    n_entries, n_features = processed_features.shape\n",
    "    \n",
    "    print(f\"Processing {n_entries} entries with {n_features} features\")\n",
    "    \n",
    "    # Step 2: Build constraint matrix for ranking\n",
    "    A_ineq, b_ineq = build_ranking_constraints(processed_features, starred_idx, epsilon)\n",
    "    \n",
    "    # Step 3: Check feasibility\n",
    "    if not check_constraint_feasibility(A_ineq, b_ineq):\n",
    "        print(\"WARNING: Constraints may be infeasible. Adjusting...\")\n",
    "        epsilon = epsilon / 10\n",
    "        A_ineq, b_ineq = build_ranking_constraints(processed_features, starred_idx, epsilon)\n",
    "    \n",
    "    # Step 4: Solve optimization\n",
    "    w_optimal = solve_constrained_optimization(A_ineq, b_ineq, w_original)\n",
    "    \n",
    "    # Step 5: Verify and post-process\n",
    "    w_final = verify_and_adjust(processed_features, starred_idx, w_optimal, epsilon)\n",
    "    \n",
    "    return w_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7d27c",
   "metadata": {},
   "source": [
    "#### The optimization constraints are built here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a569754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ranking_constraints(features, starred_idx, epsilon):\n",
    "    \"\"\"\n",
    "    Build constraint matrix: A_ineq @ w >= b_ineq ensures starred entry ranks first\n",
    "    Constraint: w^T(x* - x_i) >= epsilon for all i != starred\n",
    "    \"\"\"\n",
    "    x_starred = features[starred_idx]\n",
    "    n_entries, n_features = features.shape\n",
    "    \n",
    "    # Number of constraints = number of other entries\n",
    "    n_constraints = n_entries - 1\n",
    "    \n",
    "    A_ineq = np.zeros((n_constraints, n_features))\n",
    "    b_ineq = np.full(n_constraints, epsilon)\n",
    "    \n",
    "    constraint_idx = 0\n",
    "    for i in range(n_entries):\n",
    "        if i != starred_idx:\n",
    "            # Constraint: (x* - x_i)^T w >= epsilon\n",
    "            A_ineq[constraint_idx] = x_starred - features[i]\n",
    "            constraint_idx += 1\n",
    "    \n",
    "    return A_ineq, b_ineq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf74b23",
   "metadata": {},
   "source": [
    "#### A check to see if the chosen constraints can solve the optimization problem - if not, need to reduce the epsilon value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1f4b1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_constraint_feasibility(A_ineq, b_ineq):\n",
    "    \"\"\"\n",
    "    Check if the constraint system Aw >= b has a solution\n",
    "    \"\"\"\n",
    "    # Use linear programming to check feasibility\n",
    "    # minimize 0^T w subject to Aw >= b\n",
    "    \n",
    "    n_vars = A_ineq.shape[1]\n",
    "    c = np.zeros(n_vars)  # Objective doesn't matter for feasibility\n",
    "    \n",
    "    # Convert to standard form: -Aw <= -b\n",
    "    A_ub = -A_ineq\n",
    "    b_ub = -b_ineq\n",
    "    \n",
    "    # Add bounds to prevent unbounded solution\n",
    "    bounds = [(-1000, 1000) for _ in range(n_vars)]\n",
    "    \n",
    "    try:\n",
    "        result = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n",
    "        feasible = result.success\n",
    "        print(f\"Feasibility check: {'FEASIBLE' if feasible else 'INFEASIBLE'}\")\n",
    "        return feasible\n",
    "    except:\n",
    "        print(\"Feasibility check failed - assuming feasible\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa44916",
   "metadata": {},
   "source": [
    "#### The optimization function is built on the different optimization methods - SLSQP and trust constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9a789a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_constrained_optimization(A_ineq, b_ineq, w_original):\n",
    "    \"\"\"\n",
    "    Solve the constrained optimization problem\n",
    "    \"\"\"\n",
    "    n_features = len(w_original)\n",
    "    \n",
    "    def objective(w):\n",
    "        return np.sum((w - w_original)**2)\n",
    "    \n",
    "    def constraint_function(w):\n",
    "        return A_ineq @ w - b_ineq  # Should be >= 0\n",
    "    \n",
    "    def normalization_constraint(w):\n",
    "        return np.linalg.norm(w) - 1  # Should be = 0\n",
    "    \n",
    "    constraints = [\n",
    "        {'type': 'ineq', 'fun': constraint_function},\n",
    "        {'type': 'eq', 'fun': normalization_constraint}\n",
    "    ]\n",
    "    \n",
    "    # Start with normalized original weights\n",
    "    w0 = w_original / np.linalg.norm(w_original)\n",
    "    \n",
    "    # Try multiple optimization methods\n",
    "    methods = ['SLSQP', 'trust-constr']\n",
    "    \n",
    "    for method in methods:\n",
    "        try:\n",
    "            print(f\"Trying optimization method: {method}\")\n",
    "            result = minimize(objective, w0, constraints=constraints, \n",
    "                            method=method, options={'maxiter': 1000})\n",
    "            \n",
    "            if result.success:\n",
    "                print(f\"Optimization successful with {method}\")\n",
    "                return result.x\n",
    "            else:\n",
    "                print(f\"Method {method} failed: {result.message}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Method {method} raised exception: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Fallback: Use the constraint that matters most\n",
    "    print(\"All methods failed. Using fallback approach...\")\n",
    "    return fallback_solution(A_ineq, b_ineq, w_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5397e10",
   "metadata": {},
   "source": [
    "#### If optimization using the above methods are not possible, a different method utilizing a brute force approach trying to reduce the most violatred constraint is followed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8a905fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fallback_solution(A_ineq, b_ineq, w_original):\n",
    "    \"\"\"\n",
    "    Fallback solution when optimization fails\n",
    "    \"\"\"\n",
    "    # Find the direction that maximally satisfies constraints\n",
    "    # Use the constraint with minimum margin\n",
    "    \n",
    "    n_features = A_ineq.shape[1]\n",
    "    \n",
    "    # Average constraint direction, weighted by violation\n",
    "    w_current = w_original / np.linalg.norm(w_original)\n",
    "    \n",
    "    for iteration in range(100):\n",
    "        violations = A_ineq @ w_current - b_ineq\n",
    "        violated_indices = violations < 0\n",
    "        \n",
    "        if not np.any(violated_indices):\n",
    "            break  # All constraints satisfied\n",
    "        \n",
    "        # Move in direction of most violated constraint\n",
    "        worst_constraint_idx = np.argmin(violations)\n",
    "        direction = A_ineq[worst_constraint_idx]\n",
    "        \n",
    "        # Step in that direction\n",
    "        step_size = 0.1\n",
    "        w_new = w_current + step_size * direction\n",
    "        w_current = w_new / np.linalg.norm(w_new)\n",
    "    \n",
    "    return w_current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15a0ee",
   "metadata": {},
   "source": [
    "#### The final solution is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1edd0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_and_adjust(features, starred_idx, w_solution, epsilon):\n",
    "    \"\"\"\n",
    "    Verify the solution and make final adjustments if needed\n",
    "    \"\"\"\n",
    "    scores = features @ w_solution\n",
    "    starred_score = scores[starred_idx]\n",
    "    \n",
    "    # Check if starred entry is actually rank 1\n",
    "    other_scores = np.delete(scores, starred_idx)\n",
    "    max_other_score = np.max(other_scores)\n",
    "    \n",
    "    if starred_score <= max_other_score:\n",
    "        print(f\"WARNING: Starred score {starred_score:.6f} <= max other {max_other_score:.6f}\")\n",
    "        \n",
    "        # Force adjustment: boost starred entry's score\n",
    "        x_starred = features[starred_idx]\n",
    "        \n",
    "        # Find feature with maximum positive impact\n",
    "        best_feature_idx = np.argmax(np.abs(x_starred))\n",
    "        \n",
    "        # Slightly increase weight for that feature\n",
    "        w_adjusted = w_solution.copy()\n",
    "        adjustment = (max_other_score - starred_score + epsilon) / x_starred[best_feature_idx]\n",
    "        w_adjusted[best_feature_idx] += adjustment\n",
    "        \n",
    "        # Renormalize\n",
    "        w_final = w_adjusted / np.linalg.norm(w_adjusted)\n",
    "        \n",
    "        print(\"Applied final adjustment\")\n",
    "    else:\n",
    "        w_final = w_solution\n",
    "    \n",
    "    # Final verification\n",
    "    final_scores = features @ w_final\n",
    "    final_ranks = (-final_scores).argsort().argsort() + 1\n",
    "    \n",
    "    print(f\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Starred entry rank: {final_ranks[starred_idx]}\")\n",
    "    print(f\"Starred entry score: {final_scores[starred_idx]:.6f}\")\n",
    "    print(f\"Second highest score: {np.sort(final_scores)[-2]:.6f}\")\n",
    "    print(f\"Score margin: {final_scores[starred_idx] - np.sort(final_scores)[-2]:.6f}\")\n",
    "    \n",
    "    # Show top 5\n",
    "    top_indices = np.argsort(-final_scores)[:5]\n",
    "    print(\"\\nTop 5 entries:\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        marker = \"⭐ STARRED\" if idx == starred_idx else \"\"\n",
    "        print(f\"{i+1}. Index {idx}: {final_scores[idx]:.6f} {marker}\")\n",
    "    \n",
    "    if final_ranks[starred_idx] != 1:\n",
    "        print(f\"WARNING: Starred entry rank is {final_ranks[starred_idx]}, not 1!\")\n",
    "    \n",
    "    return w_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "76b83841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "INVERSE OPTIMIZATION\n",
      "==================================================\n",
      "Processing 53 entries with 9 features\n",
      "Feasibility check: INFEASIBLE\n",
      "WARNING: Constraints may be infeasible. Adjusting...\n",
      "Trying optimization method: SLSQP\n",
      "Method SLSQP failed: Positive directional derivative for linesearch\n",
      "Trying optimization method: trust-constr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Apziva\\Project3\\nlp_env\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:504: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  self.H.update(delta_x, delta_g)\n",
      "d:\\Apziva\\Project3\\nlp_env\\lib\\site-packages\\scipy\\optimize\\_trustregion_constr\\equality_constrained_sqp.py:203: UserWarning: Singular Jacobian matrix. Using SVD decomposition to perform the factorizations.\n",
      "  Z, LS, Y = projections(A, factorization_method)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method trust-constr failed: The maximum number of function evaluations is exceeded.\n",
      "All methods failed. Using fallback approach...\n",
      "WARNING: Starred score 1.257850 <= max other 1.283162\n",
      "Applied final adjustment\n",
      "\n",
      "=== FINAL RESULTS ===\n",
      "Starred entry rank: 9\n",
      "Starred entry score: 1.252822\n",
      "Second highest score: 1.273319\n",
      "Score margin: -0.020496\n",
      "\n",
      "Top 5 entries:\n",
      "1. Index 21: 1.277535 \n",
      "2. Index 32: 1.273319 \n",
      "3. Index 37: 1.265166 \n",
      "4. Index 10: 1.262016 \n",
      "5. Index 7: 1.260589 \n",
      "WARNING: Starred entry rank is 9, not 1!\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "def run_optimization(all_features, starred_idx, w_original):\n",
    "    \"\"\"\n",
    "    Main function to run the guaranteed rank-1 method\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"INVERSE OPTIMIZATION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    w_final = optimization_process(\n",
    "        all_features, starred_idx, w_original, \n",
    "        handle_duplicates=True, epsilon=1e-4\n",
    "    )\n",
    "    \n",
    "    return w_final\n",
    "\n",
    "\n",
    "w_original = np.array([ranker.feature_weights[f] for f in features_df.columns])\n",
    "w_new = run_optimization(all_features, random_star_idx, w_original)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
